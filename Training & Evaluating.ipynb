{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d84980-9ab4-4050-8342-a99858c7f255",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: darts in /home/talkanbar/.local/lib/python3.11/site-packages (0.33.0)\n",
      "Requirement already satisfied: holidays>=0.11.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (0.67)\n",
      "Requirement already satisfied: joblib>=0.16.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from darts) (1.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from darts) (3.7.2)\n",
      "Requirement already satisfied: nfoursid>=1.0.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (1.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from darts) (1.25.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from darts) (2.0.3)\n",
      "Requirement already satisfied: pmdarima>=1.8.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.0.4)\n",
      "Requirement already satisfied: pyod>=0.9.5 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from darts) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from darts) (1.11.1)\n",
      "Requirement already satisfied: shap>=0.40.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (0.46.0)\n",
      "Requirement already satisfied: statsforecast>=1.4 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.0.1)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (0.14.4)\n",
      "Requirement already satisfied: tbats>=1.1.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (1.1.3)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (4.12.2)\n",
      "Requirement already satisfied: xarray>=0.17.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2025.1.2)\n",
      "Requirement already satisfied: xgboost>=1.6.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.1.4)\n",
      "Requirement already satisfied: pytorch-lightning>=1.5.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.5.0.post0)\n",
      "Requirement already satisfied: tensorboardX>=2.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from darts) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from holidays>=0.11.1->darts) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /sw/arch/RHEL8/EB_production/2023/software/Pillow/10.0.0-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<=3.1,>=2.3.1 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib>=3.3.0->darts) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pandas>=1.0.5->darts) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from pandas>=1.0.5->darts) (2023.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pmdarima>=1.8.0->darts) (0.29.35)\n",
      "Requirement already satisfied: urllib3 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pmdarima>=1.8.0->darts) (1.26.16)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /sw/arch/RHEL8/EB_production/2023/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/site-packages (from pmdarima>=1.8.0->darts) (67.7.2)\n",
      "Requirement already satisfied: numba>=0.51 in /home/talkanbar/.local/lib/python3.11/site-packages (from pyod>=0.9.5->darts) (0.61.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /sw/arch/RHEL8/EB_production/2023/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from pytorch-lightning>=1.5.0->darts) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pytorch-lightning>=1.5.0->darts) (2023.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from pytorch-lightning>=1.5.0->darts) (1.6.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from pytorch-lightning>=1.5.0->darts) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests>=2.22.0->darts) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests>=2.22.0->darts) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests>=2.22.0->darts) (2023.5.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from scikit-learn>=1.0.1->darts) (3.1.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /home/talkanbar/.local/lib/python3.11/site-packages (from shap>=0.40.0->darts) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from shap>=0.40.0->darts) (2.2.1)\n",
      "Requirement already satisfied: coreforecast>=0.0.12 in /home/talkanbar/.local/lib/python3.11/site-packages (from statsforecast>=1.4->darts) (0.0.15)\n",
      "Requirement already satisfied: fugue>=0.8.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from statsforecast>=1.4->darts) (0.9.1)\n",
      "Requirement already satisfied: utilsforecast>=0.1.4 in /home/talkanbar/.local/lib/python3.11/site-packages (from statsforecast>=1.4->darts) (0.2.11)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/talkanbar/.local/lib/python3.11/site-packages (from statsmodels>=0.14.0->darts) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/talkanbar/.local/lib/python3.11/site-packages (from tensorboardX>=2.1->darts) (5.29.3)\n",
      "Requirement already satisfied: filelock in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.8.0->darts) (3.12.2)\n",
      "Requirement already satisfied: networkx in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.8.0->darts) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from torch>=1.8.0->darts) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.8.0->darts) (1.3.0)\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.3.0->darts)\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting pandas>=1.0.5 (from darts)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.8.5)\n",
      "Requirement already satisfied: triad>=0.9.7 in /home/talkanbar/.local/lib/python3.11/site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.9.8)\n",
      "Requirement already satisfied: adagio>=0.2.4 in /home/talkanbar/.local/lib/python3.11/site-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.2.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/talkanbar/.local/lib/python3.11/site-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from python-dateutil->holidays>=0.11.1->darts) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/arch/RHEL8/EB_production/2023/software/Mako/1.2.4-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->darts) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /sw/arch/RHEL8/EB_production/2023/software/aiohttp/3.8.5-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /home/talkanbar/.local/lib/python3.11/site-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (19.0.1)\n",
      "Requirement already satisfied: fs in /home/talkanbar/.local/lib/python3.11/site-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (2.4.16)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\n",
      "Installing collected packages: packaging, pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bokeh 3.7.0 requires contourpy>=1.2, but you have contourpy 1.1.0 which is incompatible.\n",
      "dask 2025.3.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed packaging-24.2 pandas-2.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b325163-f268-43df-a4e7-a197ef6ea4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"NUMEXPR_MAX_THREADS\"] = \"72\"\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mae, rmse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from pytorch_lightning import Trainer\n",
    "from darts.models import NBEATSModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts.models import RNNModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7da06d-eb66-4451-badd-7cd666f5c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/gpfs/home5/talkanbar/\"\n",
    "file_name = \"df_classified_good.pkl\" # file for selected symbols (main experiments)\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "merged_df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c8d11d-6a7a-4e02-94aa-e14a2c688f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9918123\n",
      "Number of unique symbols: 369\n"
     ]
    }
   ],
   "source": [
    "num_rows = merged_df.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "num_unique_symbols = merged_df['symbol'].nunique()\n",
    "print(\"Number of unique symbols:\", num_unique_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749e0ea-7c7c-4a77-bdb3-b16750dac48b",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbbab91-2f74-4151-a164-478aa4ec7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#many functions were used in EDA and in debugging the training process including:\n",
    "def inspect_short_symbols(df, short_symbols):\n",
    "   # To inspects the minimum and maximum 'timestamp_fixed' values for the specified short symbols in the DataFrame\n",
    "    for symbol in short_symbols:\n",
    "        symbol_df = df[df['symbol'] == symbol].sort_values('timestamp_fixed')\n",
    "        if not symbol_df.empty:\n",
    "            min_ts = symbol_df['timestamp_fixed'].min()\n",
    "            max_ts = symbol_df['timestamp_fixed'].max()\n",
    "            print(f\"Symbol: {symbol}\")\n",
    "            print(f\"  Minimum timestamp_fixed: {min_ts}\")\n",
    "            print(f\"  Maximum timestamp_fixed: {max_ts}\")\n",
    "            print(f\"  Number of rows: {len(symbol_df)}\")\n",
    "        else:\n",
    "            print(f\"Symbol '{symbol}' not found in the DataFrame.\")\n",
    "\n",
    "def identify_short_time_series(df, H, covariate_cols, input_chunk_length):\n",
    "    #Identifies symbols whose time series are too short for the given NBEATS model parameters after target shifting. \n",
    "    short_symbols = []\n",
    "    min_required_length = max(input_chunk_length, 1 + H)\n",
    "    grouped = df.groupby('symbol')\n",
    "    for symbol, group_df in grouped:\n",
    "        group_df = group_df.sort_values('timestamp_fixed').copy()\n",
    "        group_df['target'] = group_df['mid_price_usd'].shift(-H)\n",
    "        group_df_cleaned = group_df.dropna(subset=['target'] + covariate_cols)\n",
    "\n",
    "        target_series = TimeSeries.from_dataframe(\n",
    "            group_df_cleaned, time_col='timestamp_fixed', value_cols='target'\n",
    "        )\n",
    "        if len(target_series) < min_required_length:\n",
    "            short_symbols.append(symbol)\n",
    "    return short_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0545b5-5b6a-4580-9b41-2e4c178ac552",
   "metadata": {},
   "source": [
    "### Preparing the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726e1c5-a0c5-4f54-b9e4-56ca8d2713ea",
   "metadata": {},
   "source": [
    "filtering: each day:excluding last 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603b36b7-f1d8-42bd-9541-f7c7f8dda21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=merged_df\n",
    "#as explained in the paper, we excluded the last 2 hours\n",
    "df = df[df['timestamp_fixed'].dt.time < (pd.Timestamp('06:00:00').time())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cce59-c495-4f14-9fd2-38f2a7e2d8b0",
   "metadata": {},
   "source": [
    "deleting symbols that has less than 80% coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cfdecb3-d77c-48a8-8222-8c901e320120",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vol_df=df\n",
    "symbol_counts = filtered_vol_df['symbol'].value_counts()\n",
    "max_count = symbol_counts.max()\n",
    "threshold = max_count * 0.8\n",
    "symbols_to_keep = symbol_counts[symbol_counts >= threshold].index\n",
    "df_filtered3 = filtered_vol_df[filtered_vol_df['symbol'].isin(symbols_to_keep)]\n",
    "df = df_filtered3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dc0fd3f-8ee7-4abb-8d75-ddf712c1ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identify_short_time_series(df, 100, covariate_cols, 500) #if none we are good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11afd4-4f0f-425b-8817-ee0f10ba4ba6",
   "metadata": {},
   "source": [
    "# NBEATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18c94b-df3b-4524-a730-4b6cb9095e9e",
   "metadata": {},
   "source": [
    "We can select one of these settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53227e-2681-4631-8b9d-cc49959df87e",
   "metadata": {},
   "source": [
    "Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee8e075-8925-4ef0-8a5b-a23f712bf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_cols = [\n",
    "    'asks_0__price_usd', 'asks_1__price_usd', 'asks_2__price_usd',\n",
    "    'asks_3__price_usd', 'asks_4__price_usd', 'bids_0__price_usd',\n",
    "    'bids_1__price_usd', 'bids_2__price_usd', 'bids_3__price_usd',\n",
    "    'bids_4__price_usd', 'asks_0__amount_norm', 'asks_1__amount_norm',\n",
    "    'asks_2__amount_norm', 'asks_3__amount_norm', 'asks_4__amount_norm',\n",
    "    'bids_0__amount_norm', 'bids_1__amount_norm', 'bids_2__amount_norm',\n",
    "    'bids_3__amount_norm', 'bids_4__amount_norm',\n",
    "  \n",
    "  \n",
    "    'time_to_expiry_min'\n",
    "    ,'strike'\n",
    "    #, 'underlying_price'\n",
    "    ,'type_C', 'type_P'\n",
    "    , 'moneyness'\n",
    "   # 'mid_price_volatility_norm', 'total_bid_depth', 'total_ask_depth', 'order_book_depth',\n",
    "    #'relative_spread','imbalance_L1_pct','last_price', 'bid_iv', 'ask_iv', 'mark_price', 'weighted_mid_price_L1_usd_norm', 'weighted_mid_price_L2_usd_norm',\n",
    "    #   'weighted_mid_price_L3_usd_norm', 'VWMP_usd_norm', 'spread_usd_norm'\n",
    "    #,'delta', 'gamma',\n",
    "    #   'vega', 'theta', 'rho', 'moneyness'\n",
    "]\n",
    "target_col = 'mid_price_usd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9d4eb-abf5-4745-a4ad-1becc7dfd8d2",
   "metadata": {},
   "source": [
    "with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f595a26-48ae-4a5e-ae68-b451fdad82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_cols = [\n",
    "    'asks_0__price_usd', 'asks_1__price_usd', 'asks_2__price_usd',\n",
    "    'asks_3__price_usd', 'asks_4__price_usd', 'bids_0__price_usd',\n",
    "    'bids_1__price_usd', 'bids_2__price_usd', 'bids_3__price_usd',\n",
    "    'bids_4__price_usd', 'asks_0__amount_norm', 'asks_1__amount_norm',\n",
    "    'asks_2__amount_norm', 'asks_3__amount_norm', 'asks_4__amount_norm',\n",
    "    'bids_0__amount_norm', 'bids_1__amount_norm', 'bids_2__amount_norm',\n",
    "    'bids_3__amount_norm', 'bids_4__amount_norm',\n",
    " \n",
    "    'time_to_expiry_min'\n",
    "    ,'strike'\n",
    " \n",
    "    ,'type_C', 'type_P',\n",
    "'open_interest', 'last_price', 'bid_iv',\n",
    "       'ask_iv', 'mark_price', 'mark_iv',  \n",
    "       'underlying_price', 'delta', 'gamma', 'vega', 'theta', 'rho', \n",
    "      'moneyness',  \n",
    "       'underlying_return',   'imbalance_L1_usd',\n",
    "       'imbalance_L1_pct', 'imbalance_L1_rolling_mean', 'imbalance_L2_usd',\n",
    "       'imbalance_L3_usd', 'imbalance_VWMP_usd', 'spread_usd',\n",
    "       'relative_spread', 'depth_ratio', 'price_impact_ratio',\n",
    "       'total_bid_depth', 'total_ask_depth', 'order_book_depth'\n",
    "]\n",
    "target_col = 'mid_price_usd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19dd12-be4d-4903-9ca9-4e62f3b710b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#now training and evaluataion pipeline\n",
    "#  prediction horizon\n",
    "H = 100  \n",
    "\n",
    "# the  following settings are constructed so we train onoe model for all symbols\n",
    "clean_groups = {}\n",
    "for symbol, group_df in df.groupby('symbol'):\n",
    "    group_df = group_df.sort_values('timestamp_fixed').copy()\n",
    "    # Create the shifted target\n",
    "    group_df['target'] = group_df['mid_price_usd'].shift(-H)\n",
    "    group_df = group_df.dropna(subset=['target'] + covariate_cols)\n",
    "    float_cols = ['target', 'mid_price_usd'] + covariate_cols\n",
    "    group_df[float_cols] = group_df[float_cols].astype(np.float32)\n",
    "    clean_groups[symbol] = group_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "raw_target_series = {}\n",
    "raw_covariate_series = {}\n",
    "for symbol, group_df in clean_groups.items():\n",
    "    target_series = TimeSeries.from_dataframe(group_df, time_col='timestamp_fixed', value_cols='target' )\n",
    "    covariate_series = TimeSeries.from_dataframe(group_df, time_col='timestamp_fixed', value_cols=covariate_cols)\n",
    "    raw_target_series[symbol] = target_series\n",
    "    raw_covariate_series[symbol] = covariate_series\n",
    "# Parameters\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Outputs\n",
    "train_target_series = []\n",
    "test_target_series = []\n",
    "train_covariate_series = []\n",
    "test_covariate_series = []\n",
    "target_scalers = []\n",
    "all_target_series_scaled = []\n",
    "all_covariate_series_scaled = []\n",
    "symbols = list(raw_target_series.keys())\n",
    "for symbol in symbols:\n",
    "    target_series = raw_target_series[symbol]\n",
    "    covariate_series = raw_covariate_series[symbol]\n",
    "    # Split \n",
    "    split_point = int(len(target_series) * train_ratio)\n",
    "\n",
    "    # Fit scaler\n",
    "    scaler_target = Scaler()\n",
    "    scaler_covariate = Scaler()\n",
    "    train_target = target_series[:split_point]\n",
    "    train_covariate = covariate_series[:split_point]\n",
    "    target_scaled = scaler_target.fit(train_target).transform(target_series)\n",
    "    covariate_scaled = scaler_covariate.fit(train_covariate).transform(covariate_series)\n",
    "\n",
    "    target_scalers.append(scaler_target)\n",
    "\n",
    "    train_target_series.append(target_scaled[:split_point])\n",
    "    test_target_series.append(target_scaled[split_point:])\n",
    "    train_covariate_series.append(covariate_scaled[:split_point])\n",
    "    test_covariate_series.append(covariate_scaled[split_point:])\n",
    "\n",
    "    all_target_series_scaled.append(target_scaled)\n",
    "    all_covariate_series_scaled.append(covariate_scaled)\n",
    "\n",
    "#  the model\n",
    "model = NBEATSModel(\n",
    "    input_chunk_length=500,  \n",
    "    output_chunk_length=H,\n",
    "    generic_architecture=True,\n",
    "    num_stacks=2,\n",
    "    num_blocks=3,\n",
    "    num_layers=4,\n",
    "    layer_widths=512,\n",
    "    n_epochs=1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#We report metrics per symbol\n",
    "from darts.metrics import mae, rmse, mape\n",
    "\n",
    "model.fit(series=train_target_series, past_covariates=train_covariate_series, verbose=True)\n",
    "mae_scores_per_symbol = {}\n",
    "rmse_scores_per_symbol = {}\n",
    "mape_scores_per_symbol = {}\n",
    "predictions_per_symbol = {}\n",
    "\n",
    "# Evaluate \n",
    "for i, symbol in enumerate(symbols):\n",
    "    predicted = model.historical_forecasts(\n",
    "        series=all_target_series_scaled[i],\n",
    "        past_covariates=all_covariate_series_scaled[i],\n",
    "        start=len(train_target_series[i]),\n",
    "        forecast_horizon=H,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "        verbose=False  \n",
    "    )\n",
    "    predictions_per_symbol[symbol] = predicted\n",
    "\n",
    "#  per symbol\n",
    "for i, symbol in enumerate(symbols):\n",
    "    actual = target_scalers[i].inverse_transform(test_target_series[i])\n",
    "    predicted = target_scalers[i].inverse_transform(predictions_per_symbol[symbol])\n",
    "\n",
    "    mae_val = mae(actual, predicted)\n",
    "    rmse_val = rmse(actual, predicted)\n",
    "    try:\n",
    "        mape_val = mape(actual, predicted)\n",
    "    except ValueError as e:\n",
    "        print(f\"MAPE error for symbol {symbol}: {e}\")\n",
    "        mape_val = np.nan\n",
    "\n",
    "    mae_scores_per_symbol[symbol] = mae_val\n",
    "    rmse_scores_per_symbol[symbol] = rmse_val\n",
    "    mape_scores_per_symbol[symbol] = mape_val\n",
    "\n",
    "#  average metrics\n",
    "avg_mae = np.nanmean(list(mae_scores_per_symbol.values()))\n",
    "avg_rmse = np.nanmean(list(rmse_scores_per_symbol.values()))\n",
    "avg_mape = np.nanmean(list(mape_scores_per_symbol.values()))\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Symbol': list(mae_scores_per_symbol.keys()),\n",
    "    'MAE': list(mae_scores_per_symbol.values()),\n",
    "    'RMSE': list(rmse_scores_per_symbol.values()),\n",
    "    'MAPE': list(mape_scores_per_symbol.values())\n",
    "})\n",
    "\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "print(f\"Average MAE with historical_forecasts: {avg_mae:.4f}\")\n",
    "print(f\"Average RMSE with historical_forecasts: {avg_rmse:.4f}\")\n",
    "print(f\"Average MAPE with historical_forecasts: {avg_mape:.4f}\")\n",
    "\n",
    "metrics_df.to_pickle('metrics_df_one4all_goodsymbols_allfeatures_NB.pkl')\n",
    "#we did this experiment for many settings of the data (from initial experiments to main experiments) and each time we saved the metrics df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe04f3-52d6-42dd-9f00-96c35b5146bd",
   "metadata": {},
   "source": [
    "###  LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8ada8-9c35-4afe-b02e-05f5453d995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use same settings as NBEATS, except what is specific to RNN\n",
    "H = 100  # Prediction horizon\n",
    "clean_groups = {}\n",
    "\n",
    "for symbol, group_df in df.groupby('symbol'):\n",
    "    group_df = group_df.sort_values('timestamp_fixed').copy()\n",
    "    group_df['target'] = group_df['mid_price_usd'].shift(-H)\n",
    "    numeric_cols = [col for col in covariate_cols if col != 'timestamp_fixed']\n",
    "    group_df[numeric_cols + ['target', 'mid_price_usd']] = group_df[numeric_cols + ['target', 'mid_price_usd']].astype(np.float32)\n",
    "    if 'time_to_expiry_seconds' in group_df.columns:\n",
    "        group_df['time_to_expiry_seconds'] = pd.to_numeric(\n",
    "            group_df['time_to_expiry_seconds'],\n",
    "            errors='coerce'\n",
    "        ).astype(np.float32)\n",
    "    group_df = group_df.dropna(subset=['target'] + covariate_cols)\n",
    "    clean_groups[symbol] = group_df.reset_index(drop=True)\n",
    "\n",
    "raw_target_series = {}\n",
    "raw_covariate_series = {}\n",
    "\n",
    "for symbol, group_df in clean_groups.items():\n",
    "    target_series = TimeSeries.from_dataframe(\n",
    "        group_df, \n",
    "        time_col='timestamp_fixed', \n",
    "        value_cols='target'\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    covariate_series = TimeSeries.from_dataframe(\n",
    "        group_df,\n",
    "        time_col='timestamp_fixed',\n",
    "        value_cols=covariate_cols\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    raw_target_series[symbol] = target_series\n",
    "    raw_covariate_series[symbol] = covariate_series\n",
    "\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_target_series = []\n",
    "test_target_series = []\n",
    "train_covariate_series = []\n",
    "test_covariate_series = []\n",
    "symbols = list(raw_target_series.keys())\n",
    "for symbol in symbols:\n",
    "    target_series = raw_target_series[symbol]\n",
    "    covariate_series = raw_covariate_series[symbol]\n",
    "    \n",
    "    split_point = int(len(target_series) * train_ratio)\n",
    "\n",
    "    scaler_target = Scaler()\n",
    "    scaler_covariate = Scaler()\n",
    "    \n",
    "    target_scaled = scaler_target.fit_transform(target_series).astype(np.float32)\n",
    "    covariate_scaled = scaler_covariate.fit_transform(covariate_series).astype(np.float32)\n",
    "    \n",
    "    train_target_series.append(target_scaled[:split_point])\n",
    "    test_target_series.append(target_scaled[split_point:])\n",
    "    train_covariate_series.append(covariate_scaled[:split_point])\n",
    "    test_covariate_series.append(covariate_scaled[split_point:])\n",
    "\n",
    "\n",
    "rnn_model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=500,\n",
    "    output_chunk_length=H,\n",
    "    hidden_dim=128,\n",
    "    n_rnn_layers=3,\n",
    "    dropout=0.1,\n",
    "    batch_size=32,\n",
    "    n_epochs=1,\n",
    "    random_state=42,\n",
    "    training_length=500 + H,\n",
    "    optimizer_kwargs={'lr': 1e-3},\n",
    "    force_reset=True,\n",
    "    pl_trainer_kwargs={\n",
    "        'precision': '32-true',  \n",
    "        'accelerator': 'auto'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Training\n",
    "rnn_model.fit(\n",
    "    series=train_target_series,\n",
    "    future_covariates=train_covariate_series,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "mae_scores_per_symbol_rnn = {}\n",
    "rmse_scores_per_symbol_rnn = {}\n",
    "mape_scores_per_symbol_rnn = {}\n",
    "predictions_per_symbol_rnn = {}\n",
    "\n",
    "for i, symbol in enumerate(symbols):\n",
    "    predicted = rnn_model.historical_forecasts(\n",
    "        series=all_target_series_scaled[i],\n",
    "        future_covariates=all_covariate_series_scaled[i], \n",
    "        start=len(train_target_series[i]),\n",
    "        forecast_horizon=H,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    predictions_per_symbol_rnn[symbol] = predicted\n",
    "\n",
    "for i, symbol in enumerate(symbols):\n",
    "    actual = target_scalers[i].inverse_transform(test_target_series[i])\n",
    "    predicted = target_scalers[i].inverse_transform(predictions_per_symbol_rnn[symbol])\n",
    "\n",
    "    mae_val = mae(actual, predicted)\n",
    "    rmse_val = rmse(actual, predicted)\n",
    "    try:\n",
    "        mape_val = mape(actual, predicted)\n",
    "    except ValueError as e:\n",
    "        print(f\"MAPE error for symbol {symbol}: {e}\")\n",
    "        mape_val = np.nan\n",
    "\n",
    "    mae_scores_per_symbol_rnn[symbol] = mae_val\n",
    "    rmse_scores_per_symbol_rnn[symbol] = rmse_val\n",
    "    mape_scores_per_symbol_rnn[symbol] = mape_val\n",
    "\n",
    "avg_mae_rnn = np.nanmean(list(mae_scores_per_symbol_rnn.values()))\n",
    "avg_rmse_rnn = np.nanmean(list(rmse_scores_per_symbol_rnn.values()))\n",
    "avg_mape_rnn = np.nanmean(list(mape_scores_per_symbol_rnn.values()))\n",
    "\n",
    "\n",
    "metrics_df_rnn = pd.DataFrame({\n",
    "    'Symbol': list(mae_scores_per_symbol_rnn.keys()),\n",
    "    'MAE_RNN': list(mae_scores_per_symbol_rnn.values()),\n",
    "    'RMSE_RNN': list(rmse_scores_per_symbol_rnn.values()),\n",
    "    'MAPE_RNN': list(mape_scores_per_symbol_rnn.values())\n",
    "})\n",
    "\n",
    "\n",
    "print(metrics_df_rnn)\n",
    "\n",
    "print(\"\\n--- RNN Average Metrics ---\")\n",
    "print(f\"RNN Average MAE: {avg_mae_rnn:.4f}\")\n",
    "print(f\"RNN Average RMSE: {avg_rmse_rnn:.4f}\")\n",
    "print(f\"RNN Average MAPE: {avg_mape_rnn:.4f}%\")\n",
    "\n",
    "metrics_df_rnn.to_pickle('metrics_one4all_10days_raw_RNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46ad50bc-6b12-4a25-a29b-9034329303a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/gpfs/home5/talkanbar/\"\n",
    "file_name = \"df_classified_good.pkl\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "df.to_pickle(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
